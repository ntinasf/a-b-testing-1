{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Test Analysis\n",
    "\n",
    "### Test Design and Sample Size Determination\n",
    "\n",
    "We begin with a classic A/B test to compare the performance of the two button designs. When designing the test, we must carefully consider our tolerance for different types of errors:\n",
    "\n",
    "- **Type I Error (False Positive)**: Incorrectly detecting an effect when none exists\n",
    "- **Type II Error (False Negative)**: Failing to detect a real effect\n",
    "\n",
    "In our case, given that:\n",
    "1. Button design changes are low-cost and easily reversible\n",
    "2. Missing a 25% improvement represents significant lost opportunity\n",
    "3. Implementation costs are minimal\n",
    "\n",
    "We conclude that Type II errors are more costly than Type I errors. This leads us to select:\n",
    "- Confidence Level: 95% (α = 0.05)\n",
    "- Statistical Power: 90% (β = 0.10)\n",
    "- Minimum Detectable Effect (MDE): 25% relative improvement\n",
    "- Baseline CTR: 7%\n",
    "\n",
    "Using these parameters in a [sample size calculator](https://www.evanmiller.org/ab-testing/sample-size.html), we determine that we need **4,664 samples per variant** to achieve the desired statistical properties.\n",
    "\n",
    "**Experiment Duration**\n",
    "  - Running time: 2 weeks\n",
    "  - Approximately 10,000 visitors expected\n",
    "  - The experiment will stop when the required number of samples has been collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.stats import beta, norm\n",
    "from models.visualizations import plot_cumulative_reward\n",
    "from statsmodels.stats.proportion import test_proportions_2indep, confint_proportions_2indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the working directory\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm           ab_test\n",
       "true_ctr_a           0.0702\n",
       "true_ctr_b           0.1021\n",
       "bandit_ctr_a       0.066582\n",
       "bandit_ctr_b            0.1\n",
       "button_a_clicks         313\n",
       "button_a_views         4701\n",
       "button_b_clicks         470\n",
       "button_b_views         4700\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the simulation data\n",
    "results_ab = pd.read_csv(\"data/ab_test_results.csv\")\n",
    "results_ab = pd.Series(results_ab.values[0], index=results_ab.columns)\n",
    "results_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Hypotheses\n",
    "\n",
    "Let `δ = CTR_B - CTR_A` represent the difference in click-through rates and `MDE = 0.0175`.\n",
    "\n",
    "**Null Hypothesis (H₀)**: δ ≤ MDE  \n",
    "\"The new design (B) does not provide a meaningful improvement over the current design (A)\"\n",
    "\n",
    "**Alternative Hypothesis (H₁)**: δ > MDE  \n",
    "\"The new design (B) provides an improvement of at least 1.75 percentage points over the current design (A)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "P-value: 0.0026\n",
      "95% Confidence Interval for CTR_B - CTR_A: [0.022, 0.045]\n",
      "\n",
      "Conclusion: Reject H₀\n",
      "Evidence suggests the new design provides improvement greater than 25%\n"
     ]
    }
   ],
   "source": [
    "MDE = 0.0175\n",
    "CONFIDENCE_LEVEL = 0.95\n",
    "\n",
    "_, p_value = test_proportions_2indep(count1=results_ab.loc[\"button_b_clicks\"],\n",
    "                                        nobs1=results_ab.loc[\"button_b_views\"],\n",
    "                                        count2=results_ab.loc[\"button_a_clicks\"],\n",
    "                                        nobs2=results_ab.loc[\"button_a_views\"],\n",
    "                                        value=MDE,\n",
    "                                        compare=\"diff\",\n",
    "                                        alternative=\"larger\")\n",
    "\n",
    "lower, upper = confint_proportions_2indep(count1=results_ab.loc[\"button_b_clicks\"],\n",
    "                                        nobs1=results_ab.loc[\"button_b_views\"],\n",
    "                                        count2=results_ab.loc[\"button_a_clicks\"],\n",
    "                                        nobs2=results_ab.loc[\"button_a_views\"],\n",
    "                                        compare=\"diff\",\n",
    "                                        alpha= 1-CONFIDENCE_LEVEL)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"95% Confidence Interval for CTR_B - CTR_A: [{lower:.3f}, {upper:.3f}]\")\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 1 - CONFIDENCE_LEVEL:\n",
    "   print(\"\\nConclusion: Reject H₀\")\n",
    "   print(f\"Evidence suggests the new design provides relative improvement greater than 25%\")\n",
    "else:\n",
    "   print(\"\\nConclusion: Fail to reject H₀\")\n",
    "   print(\"Insufficient evidence for meaningful improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "The statistical analysis provides strong evidence in favor of the new button design (B):\n",
    "\n",
    "1. **P-value**\n",
    "   - The p-value of 0.0026 is well below our significance level of 0.05\n",
    "   - This means that the improvement we observed is very unlikely to have occurred by chance\n",
    "   - We can confidently reject the null hypothesis\n",
    "\n",
    "2. **Confidence Interval**\n",
    "   - The 95% confidence interval [0.022, 0.045] tells us that:\n",
    "     - At worst, we expect a 2.2% (absolute) increase in CTR\n",
    "     - At best, we expect a 4.5% (absolute) increase in CTR\n",
    "   - Notably, the entire interval lies above our minimum detectable effect of 0.0175\n",
    "   - This means even our most conservative estimate exceeds our target improvement\n",
    "   - Also not that the true difference of CTRs (3%) lies inside this interval\n",
    "\n",
    "3. **Practical Significance**\n",
    "   - The findings suggest a substantial improvement in user engagement\n",
    "   - They are both statistically significant and practically meaningful\n",
    "\n",
    "Given the above, implementing the new button design (B) appears to be a well-supported decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true difference of ctrs lies inside this interval is likely to be inside here 95% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next Recommend rolling out the new button design.. Document findings clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling Analysis - Implementation 1: Initial Exploration Period\n",
    "\n",
    "### Approach Overview\n",
    "Thompson Sampling (TS) is a probabilistic algorithm that balances exploration and exploitation in decision-making. We'll examine two variations of TS, starting with an implementation that emphasizes early exploration.\n",
    "\n",
    "### Design Choices\n",
    "1. **Initial Exploration Phase**\n",
    "   - First 600 visitors randomly assigned to variants\n",
    "   - Provides unbiased baseline data\n",
    "   - Ensures sufficient initial learning period\n",
    "\n",
    "2. **Prior Selection**\n",
    "   - Using uninformative Beta(1,1) priors for both variants\n",
    "   - Represents complete initial uncertainty\n",
    "\n",
    "3. **Algorithm Phases**\n",
    "   - Phase 1: Random allocation (n=600)\n",
    "   - Phase 2: Thompson Sampling takes over\n",
    "   - Transition based on collected data\n",
    "\n",
    "4. **Experiment Duration**\n",
    "  - Running time: 2 weeks\n",
    "  - Matches classic A/B test duration\n",
    "  - Allows fair comparison between methods\n",
    "  - Approximately 10,000 visitors expected\n",
    "\n",
    "\n",
    "This approach allows us to:\n",
    "- Build knowledge from scratch without historical assumptions\n",
    "- Monitor current user behavior objectively\n",
    "- Transition smoothly to data-driven allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm          TS_min_exp\n",
       "true_ctr_a             0.0702\n",
       "true_ctr_b             0.1021\n",
       "bandit_ctr_a         0.066176\n",
       "bandit_ctr_b         0.103873\n",
       "button_a_clicks            36\n",
       "button_a_views            544\n",
       "button_b_clicks           920\n",
       "button_b_views           8857\n",
       "a_alpha                    37\n",
       "a_beta                    509\n",
       "b_alpha                   921\n",
       "b_beta                   7938\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the simulation data\n",
    "results_TS_min_exp = pd.read_csv(\"data/TS_min_exp_results.csv\")\n",
    "results_TS_min_exp = pd.Series(results_TS_min_exp.values[0], index=results_TS_min_exp.columns)\n",
    "results_TS_min_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability Analysis:\n",
      "P(B > A): 0.998\n",
      "P(B > A + MDE): 0.944\n",
      "\n",
      "95% Credible Interval for (B-A): [0.013, 0.057]\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo simulation for posterior probability analysis\n",
    "n_samples = 10000\n",
    "\n",
    "# Generate samples from final posterior distributions\n",
    "sample_a = np.random.beta(results_TS_min_exp.loc[\"a_alpha\"], \n",
    "                         results_TS_min_exp.loc[\"a_beta\"], \n",
    "                         n_samples)\n",
    "sample_b = np.random.beta(results_TS_min_exp.loc[\"b_alpha\"], \n",
    "                         results_TS_min_exp.loc[\"b_beta\"], \n",
    "                         n_samples)\n",
    "\n",
    "# Calculate probabilities of interest\n",
    "prob_b_better = (sample_b > sample_a).mean()\n",
    "prob_b_better_mde = (sample_b > (sample_a + MDE)).mean()\n",
    "\n",
    "print(f\"\\nProbability Analysis:\")\n",
    "print(f\"P(B > A): {prob_b_better:.3f}\")\n",
    "print(f\"P(B > A + MDE): {prob_b_better_mde:.3f}\")\n",
    "\n",
    "# Calculate credible interval for the difference\n",
    "diff_samples = sample_b - sample_a\n",
    "credible_interval = np.percentile(diff_samples, [2.5, 97.5])\n",
    "print(f\"\\n95% Credible Interval for (B-A): [{credible_interval[0]:.3f}, {credible_interval[1]:.3f}]\")\n",
    "\n",
    "# 95% credible interval for button B posterior\n",
    "lower, upper =beta.ppf([0.025, 0.975], a=results_TS_min_exp.loc[\"b_alpha\"], b=results_TS_min_exp.loc[\"b_beta\"])\n",
    "print(f\"\\n95% Credible Interval for (B): [{lower:.3f}, {upper:.3f}]\")\n",
    "\n",
    "# 95% credible interval for button A posterior\n",
    "lower, upper =beta.ppf([0.025, 0.975], a=results_TS_min_exp.loc[\"a_alpha\"], b=results_TS_min_exp.loc[\"a_beta\"])\n",
    "print(f\"\\n95% Credible Interval for (A): [{lower:.3f}, {upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "The analysis provides strong evidence supporting the effectiveness of Button B and the Thompson Sampling algorithm:\n",
    "\n",
    "1. **Performance**\n",
    "  - 99.8% probability that Button B outperforms Button A\n",
    "  - 94.4% probability that the improvement exceeds our minimum detectable effect (1.75%)\n",
    "  - CTR estimates are almost identical with those of the A/B test method\n",
    "  - These high probabilities indicate strong evidence for meaningful improvement\n",
    "\n",
    "2. **Credible Interval**\n",
    "  - The 95% credible interval for the difference [0.013, 0.057] indicates:\n",
    "    - At minimum, a 1.3% (absolute) increase in CTR\n",
    "    - At maximum, a 5.7% (absolute) increase in CTR\n",
    "  - The interval for Button B's CTR [0.098, 0.110] contains the true value (0.10)\n",
    "    - Demonstrates algorithm's accuracy in estimating true performance\n",
    "\n",
    "3. **Decision Confidence**\n",
    "  - The lower bound (1.3%) is slightly below our MDE (1.75%)\n",
    "  - However, the high probability of exceeding MDE (94.4%) suggests this is not concerning\n",
    "  - The narrow credible interval for Button B indicates precise estimation\n",
    "\n",
    "4. **Algorithm Performance**\n",
    "  - Successfully identified the better variant\n",
    "  - Provided accurate CTR estimates\n",
    "  - Generated sufficient evidence for decision-making\n",
    "  - Balanced exploration and exploitation effectively\n",
    "\n",
    "These results strongly support implementing Button B, with high confidence in both the statistical and practical significance of the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling Analysis - Implementation 2: Informed priors with smaller sample size\n",
    "\n",
    "### Approach Overview\n",
    "In this second implementation, we leverage our historical knowledge while maintaining Thompson Sampling's adaptive properties. This approach demonstrates how prior information can be incorporated into the decision-making process.\n",
    "\n",
    "### Design Choices\n",
    "1. **Informed Prior for Button A**\n",
    "  - Beta(6, 78) prior reflects historical 7% CTR\n",
    "  - Parameters chosen to:\n",
    "    - Center around known performance\n",
    "    - Allow sufficient variance for exploration (not too strong to dominate new data)\n",
    "    - Avoid over-confidence in historical data\n",
    "\n",
    "2. **Algorithm Configuration**\n",
    "  - No initial exploration period\n",
    "  - Thompson Sampling active from start\n",
    "  - Relies on prior knowledge to guide early decisions\n",
    "\n",
    "3. **Experiment Duration**\n",
    "  - Running time: 1 week\n",
    "  - Approximately 5,000 visitors expected\n",
    "  - Shorter timeline than previous implementations\n",
    "  - Tests algorithm's efficiency with time constraints\n",
    "\n",
    "This implementation aims to:\n",
    "- Leverage existing knowledge effectively\n",
    "- Test algorithm performance under time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm          TS_priors\n",
       "true_ctr_a            0.0702\n",
       "true_ctr_b            0.1021\n",
       "bandit_ctr_a         0.07619\n",
       "bandit_ctr_b        0.099872\n",
       "button_a_clicks           24\n",
       "button_a_views           315\n",
       "button_b_clicks          468\n",
       "button_b_views          4686\n",
       "a_alpha                   30\n",
       "a_beta                   369\n",
       "b_alpha                  469\n",
       "b_beta                  4219\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the simulation data\n",
    "results_TS_priors = pd.read_csv(\"data/TS_priors_results.csv\")\n",
    "results_TS_priors = pd.Series(results_TS_priors.values[0], index=results_TS_priors.columns)\n",
    "results_TS_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability Analysis:\n",
      "P(B > A): 0.955\n",
      "P(B > A + MDE): 0.714\n",
      "\n",
      "95% Credible Interval for (B-A): [-0.005, 0.050]\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo simulation for posterior probability analysis\n",
    "n_samples = 10000\n",
    "\n",
    "# Generate samples from final posterior distributions\n",
    "sample_a = np.random.beta(results_TS_priors.loc[\"a_alpha\"], \n",
    "                         results_TS_priors.loc[\"a_beta\"], \n",
    "                         n_samples)\n",
    "sample_b = np.random.beta(results_TS_priors.loc[\"b_alpha\"], \n",
    "                         results_TS_priors.loc[\"b_beta\"], \n",
    "                         n_samples)\n",
    "\n",
    "# Calculate probabilities of interest\n",
    "prob_b_better = (sample_b > sample_a).mean()\n",
    "prob_b_better_mde = (sample_b > (sample_a + MDE)).mean()\n",
    "\n",
    "print(f\"\\nProbability Analysis:\")\n",
    "print(f\"P(B > A): {prob_b_better:.3f}\")\n",
    "print(f\"P(B > A + MDE): {prob_b_better_mde:.3f}\")\n",
    "\n",
    "# Calculate credible interval for the difference\n",
    "diff_samples = sample_b - sample_a\n",
    "credible_interval = np.percentile(diff_samples, [2.5, 97.5])\n",
    "print(f\"\\n95% Credible Interval for (B-A): [{credible_interval[0]:.3f}, {credible_interval[1]:.3f}]\")\n",
    "\n",
    "# 95% credible interval for button B posterior\n",
    "lower, upper =beta.ppf([0.025, 0.975], a=results_TS_priors.loc[\"b_alpha\"], b=results_TS_priors.loc[\"b_beta\"])\n",
    "print(f\"\\n95% Credible Interval for (B): [{lower:.3f}, {upper:.3f}]\")\n",
    "\n",
    "# 95% credible interval for button A posterior\n",
    "lower, upper =beta.ppf([0.025, 0.975], a=results_TS_priors.loc[\"a_alpha\"], b=results_TS_priors.loc[\"a_beta\"])\n",
    "print(f\"\\n95% Credible Interval for (A): [{lower:.3f}, {upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "The analysis reveals interesting insights about leveraging historical knowledge in Thompson Sampling:\n",
    "\n",
    "1. **Prior Effectiveness**\n",
    "  - Button A's estimated CTR (7.62%) slightly overestimates true CTR (7.02%) but still is a close estimate\n",
    "  - Credible interval for A [0.051, 0.103] shows higher uncertainty than previous implementation\n",
    "  - Prior knowledge successfully guided early decisions towards the better choice\n",
    "\n",
    "2. **Performance**\n",
    "  - 95.5% probability that Button B outperforms A\n",
    "  - 71.4% probability of exceeding MDE (1.75%)\n",
    "  - Less definitive than previous implementation, but achieved in half the time\n",
    "\n",
    "3. **Sample Allocation**\n",
    "  - Strong preference for Button B (4,686 views vs 315)\n",
    "  - Algorithm quickly identified promising variant\n",
    "  - Efficient resource allocation despite shorter runtime\n",
    "\n",
    "4. **Credible intervals**\n",
    "  - Button B's credible interval [0.092, 0.109] contains true CTR (0.102)\n",
    "  - Difference interval [-0.005, 0.050] shows more uncertainty about the true difference between CTRs\n",
    "\n",
    "5. **Time-Efficiency Trade-off**\n",
    "  - Achieved reasonable certainty in one week\n",
    "  - Less definitive than two-week implementation\n",
    "  - Demonstrates value of informed priors in accelerating decisions\n",
    "\n",
    "This implementation shows promise for scenarios where:\n",
    "- Historical data is reliable\n",
    "- Quick decisions are needed\n",
    "- Some uncertainty is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Progress Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dec_1 = pd.read_csv(\"data/TS_min_exp_decisions.csv\")\n",
    "dec_1 = dec_1.values.flatten()\n",
    "\n",
    "dec_2 = pd.read_csv(\"data/TS_priors_decisions.csv\")\n",
    "dec_2 = dec_2.values.flatten()\n",
    "\n",
    "dec_3 = pd.read_csv(\"data/ab_simulation_decisions.csv\")\n",
    "dec_3 = dec_3.values.flatten()\n",
    "\n",
    "dec_4 = pd.read_csv(\"data/UCB1_decisions.csv\")\n",
    "dec_4 = dec_4.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_reward(true_ctrs=[results_TS_min_exp.loc[\"true_ctr_a\"], results_TS_min_exp.loc[\"true_ctr_b\"]],\n",
    "                       decisions=[dec_1, dec_2, dec_3, dec_4],\n",
    "                       alg_names=[\"TS_min_exp\", \"TS_priors\", \"ab_test\", \"UCB 1\"],\n",
    "                       save_path=\"data/figures\"\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cumulative Rewards](../data/figures/cumulative_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative rewards graph reveals important insights about the performance and characteristics of each implementation:\n",
    "\n",
    "1. **Early Stage Behavior (0-600 trials)**\n",
    "   - A/B test and TS with minimum exploration (TS_min_exp) track closely due to their random allocation phase\n",
    "   - UCB1 and TS with priors (TS_priors) show similar aggressive exploration patterns\n",
    "   - All algorithms exhibit expected initial volatility\n",
    "\n",
    "2. **Mid-Stage Adaptation (600-2000 trials)**\n",
    "   - TS_min_exp diverges positively from A/B test after exploration phase\n",
    "   - UCB1 demonstrates strong performance, possibly benefiting from its confidence bounds approach\n",
    "   - TS_priors maintains competitive performance despite informed priors for Button A\n",
    "\n",
    "3. **Convergence Phase (2000+ trials)**\n",
    "   - All adaptive algorithms (TS_min_exp, TS_priors, UCB1) converge toward optimal rate (0.10)\n",
    "   - A/B test plateaus at suboptimal performance (~0.085)\n",
    "   - TS implementations show more stable convergence compared to UCB1's oscillations\n",
    "\n",
    "4. **Key Observations**\n",
    "   - Adaptive algorithms clearly outperform static A/B testing\n",
    "   - Both TS implementations achieve similar final performance through different paths\n",
    "   - UCB1's more aggressive exploration leads to higher variance\n",
    "   - The cost of A/B test's fixed allocation strategy is clearly visible in lost reward\n",
    "\n",
    "5. **Long-term Efficiency**\n",
    "   - All adaptive methods eventually identify and exploit the better option\n",
    "   - TS_priors achieves comparable performance with half the trials\n",
    "   - The gap between adaptive and static approaches widens over time\n",
    "\n",
    "\n",
    "   from 300 to 600 adaptive algorithms seem to exploit clicks otherwise lost by static algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_5000 = [dec_1[:5000], dec_2[:5000], dec_3[:5000], dec_4[:5000]]\n",
    "rewards = []\n",
    "win_rates = []\n",
    "for i, dec in enumerate(decisions_5000):\n",
    "    rewards.append(np.cumsum(dec))\n",
    "    win_rates.append(rewards[i] / (np.arange(len(dec))+1))\n",
    "\n",
    "decisions_10000 = [dec_1, dec_3]\n",
    "for i, dec in enumerate(decisions_5000):\n",
    "    rewards.append(np.cumsum(dec))\n",
    "    win_rates.append(rewards[i] / (np.arange(len(dec))+1))\n",
    "\n",
    "print(f\"% Diffence between TS_min_exp - ab_test at 10000 samples: {((win_rates[5][-1] - win_rates[6][-1]) / win_rates[6][-1]*100):.2f}%\")\n",
    "print(f\"% Diffence between TS_priors - TS_min_exp at 5000 samples: {((win_rates[1][-1] - win_rates[0][-1]) / win_rates[0][-1]*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative Analysis of Posterior Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Posterior Grid](../data/figures/TS_min_exp_posterior_grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Posterior Grid 2](../data/figures/TS_priors_posterior_grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Stage (50 iterations)\n",
    "- TS_priors exhibits higher density for Button A, reflecting our informative prior (7% CTR)\n",
    "- In both cases, there is significant overlap between distributions, indicating high uncertainty\n",
    "\n",
    "#### Early-Mid Stage (150 iterations)\n",
    "- TS_min_exp shows slight overestimation of both CTRs due to random sampling\n",
    "- TS_priors demonstrates more accurate estimation as it collects more samples for B\n",
    "\n",
    "#### Mid Stage (500 iterations)\n",
    "- TS_min_exp concludes its exploration phase with higher certainty about Button A\n",
    "- TS_priors shows more confidence in Button B's distribution\n",
    "- Both implementations begin showing clear separation between variants\n",
    "\n",
    "#### Convergence Stage (1500-5000 iterations)\n",
    "1. Distribution Characteristics:\n",
    "   - Both implementations converge to similar shapes\n",
    "   - Button B consistently shows higher, narrower peaks\n",
    "   - Button A distributions maintain wider spread due to fewer samples\n",
    "\n",
    "2. Key Differences:\n",
    "   - TS_priors achieves tighter distributions with fewer total samples\n",
    "   - Final variance differences reflect adaptive sample allocation\n",
    "   - Both successfully identify the superior variant, but through different paths\n",
    "\n",
    "The evolution demonstrates how different initialization strategies (random vs informed) ultimately lead to similar conclusions, with TS_priors potentially offering faster convergence at the cost of some exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Our analysis demonstrates several key findings:\n",
    "\n",
    "1. **Algorithm Performance and Implementation Trade-offs**\n",
    "   - Classic A/B testing reached higly significant results, but at the cost of lost opportunity\n",
    "   - Thompson Sampling effectively balanced exploration/exploitation\n",
    "   - Adaptive methods seem preferable over classic A/B testing for the task\n",
    "   - Both TS implementations reached similar conclusions through different paths\n",
    "   - TS with minimum exploration: More thorough but requires longer runtime\n",
    "   - TS with informed priors: Faster decisions with acceptable confidence\n",
    "   - Choice depends on business constraints and prior knowledge reliability\n",
    "\n",
    "2. **Statistical Insights**\n",
    "   - High confidence in Button B's superiority across all methods\n",
    "   - Adaptive methods achieved higher cumulative rewards\n",
    "   - Prior knowledge can effectively accelerate decision-making\n",
    "\n",
    "4. **Practical Implications**\n",
    "   - For this use case, Thompson Sampling offers clear advantages over A/B testing\n",
    "   - When historical data is reliable, informed priors can reduce testing time\n",
    "   - Monitoring posterior evolution and cumulative rewards provides insight into decision confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab_testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
